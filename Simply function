def tanh(x):
    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))
    
def sigmoid(x):
    return 1.0 / (1.0 + np.exp(-x))
 
def softmax(x):
    denom = np.sum(np.exp(x))
    return np.exp(x) / denom
